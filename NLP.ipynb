{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1Lsp6YvC1o3Mbv5xmaD5QYAUtvkps7IlU","authorship_tag":"ABX9TyNZxyO5eEcx41VwGAPSXp0j"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","source":["import os\n","import torch\n","from torch import nn\n","import torchtext.vocab as Vocab\n","import torch.utils.data as Data\n","import  torch.nn.functional as F\n","\n","import sys\n","sys.path.append(\"..\") \n","import d2lzh_pytorch as d2l\n","\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","DATA_ROOT = \"/content/drive/MyDrive/NLP\"\n","print(torch.__version__, device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SpvFmLSYirq0","executionInfo":{"status":"ok","timestamp":1673531269468,"user_tz":-480,"elapsed":295,"user":{"displayName":"万万仕文","userId":"18414854955088658758"}},"outputId":"a9dcc1ea-17d2-4ee8-b9e3-532845390c23"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["1.13.1+cu116 cuda\n"]}]},{"cell_type":"code","source":["def corr1d(X, K):\n","   w = K.shape[0]\n","   Y = torch.zeros((X.shape[0] - w + 1))\n","   for i in range(Y.shape[0]):\n","       Y[i] = (X[i: i + w] * K).sum()\n","   return Y"],"metadata":{"id":"fJC_g0aIOBWA","executionInfo":{"status":"ok","timestamp":1673531272932,"user_tz":-480,"elapsed":744,"user":{"displayName":"万万仕文","userId":"18414854955088658758"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["def corr1d_multi_in(X, K):\n","    # 首先沿着X和K的第0维（通道维）遍历并计算一维互相关结果。然后将所有结果堆叠起来沿第0维累加\n","  return torch.stack([corr1d(x, k) for x, k in zip(X, K)]).sum(dim=0)\n","\n","X = torch.tensor([[0, 1, 2, 3, 4, 5, 6],\n","              [1, 2, 3, 4, 5, 6, 7],\n","              [2, 3, 4, 5, 6, 7, 8]])\n","K = torch.tensor([[1, 2], [3, 4], [-1, -3]])\n","corr1d_multi_in(X, K)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pC1J-pRjOGBz","executionInfo":{"status":"ok","timestamp":1673531275069,"user_tz":-480,"elapsed":591,"user":{"displayName":"万万仕文","userId":"18414854955088658758"}},"outputId":"348f09a0-c77d-4626-d554-a876f72b711b"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([ 2.,  8., 14., 20., 26., 32.])"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["class GlobalMaxPool1d(nn.Module):\n","  def __init__(self):\n","      super(GlobalMaxPool1d, self).__init__()\n","  def forward(self, x):\n","         # x shape: (batch_size, channel, seq_len)\n","     return F.max_pool1d(x, kernel_size=x.shape[2]) # shape: (batch_size, channel, 1)"],"metadata":{"id":"9DBjRdrmOPsL","executionInfo":{"status":"ok","timestamp":1673531277220,"user_tz":-480,"elapsed":409,"user":{"displayName":"万万仕文","userId":"18414854955088658758"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["!pip install torchtext==0.4.0"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":472},"id":"Rgvt_Rr1Szj9","executionInfo":{"status":"ok","timestamp":1673531222181,"user_tz":-480,"elapsed":4392,"user":{"displayName":"万万仕文","userId":"18414854955088658758"}},"outputId":"e3bba94b-1fda-4289-dec5-7a92584153e4"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting torchtext==0.4.0\n","  Downloading torchtext-0.4.0-py3-none-any.whl (53 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 KB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchtext==0.4.0) (2.25.1)\n","Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from torchtext==0.4.0) (1.13.1+cu116)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from torchtext==0.4.0) (4.64.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from torchtext==0.4.0) (1.15.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchtext==0.4.0) (1.21.6)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.4.0) (4.0.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.4.0) (2.10)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.4.0) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.4.0) (2022.12.7)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch->torchtext==0.4.0) (4.4.0)\n","Installing collected packages: torchtext\n","  Attempting uninstall: torchtext\n","    Found existing installation: torchtext 0.14.1\n","    Uninstalling torchtext-0.14.1:\n","      Successfully uninstalled torchtext-0.14.1\n","Successfully installed torchtext-0.4.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["torchtext"]}}},"metadata":{}}]},{"cell_type":"code","source":["import torchtext;print(torchtext.__version__)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WRU1BEFhRUNe","executionInfo":{"status":"ok","timestamp":1673531259724,"user_tz":-480,"elapsed":900,"user":{"displayName":"万万仕文","userId":"18414854955088658758"}},"outputId":"0dc0d416-8166-4313-86c1-54b39665c2a1"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["0.4.0\n"]}]},{"cell_type":"code","source":["batch_size = 64\n","train_data = d2l.read_imdb('train', data_root=os.path.join(DATA_ROOT, \"aclImdb\"))\n","test_data = d2l.read_imdb('test', data_root=os.path.join(DATA_ROOT, \"aclImdb\"))\n","vocab = d2l.get_vocab_imdb(train_data)\n","train_set = Data.TensorDataset(*d2l.preprocess_imdb(train_data, vocab))\n","test_set = Data.TensorDataset(*d2l.preprocess_imdb(test_data, vocab))\n","train_iter = Data.DataLoader(train_set, batch_size, shuffle=True)\n","test_iter = Data.DataLoader(test_set, batch_size)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4PWS2hGaOTK1","executionInfo":{"status":"ok","timestamp":1673531844230,"user_tz":-480,"elapsed":562642,"user":{"displayName":"万万仕文","userId":"18414854955088658758"}},"outputId":"f618b212-beff-4235-a56f-94d9d0e1d224"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 2295/2295 [00:25<00:00, 90.59it/s]  \n","100%|██████████| 12500/12500 [02:37<00:00, 79.51it/s]  \n","100%|██████████| 12500/12500 [02:14<00:00, 92.63it/s]  \n","100%|██████████| 12500/12500 [02:24<00:00, 86.54it/s]  \n"]}]},{"cell_type":"code","source":["class TextCNN(nn.Module):\n","    def __init__(self, vocab, embed_size, kernel_sizes, num_channels):\n","        super(TextCNN, self).__init__()\n","        self.embedding = nn.Embedding(len(vocab), embed_size)\n","        # 不参与训练的嵌入层\n","        self.constant_embedding = nn.Embedding(len(vocab), embed_size)\n","        self.dropout = nn.Dropout(0.5)\n","        self.decoder = nn.Linear(sum(num_channels), 2)\n","        # 时序最大池化层没有权重，所以可以共用一个实例\n","        self.pool = GlobalMaxPool1d()\n","        self.convs = nn.ModuleList()  # 创建多个一维卷积层\n","        for c, k in zip(num_channels, kernel_sizes):\n","            self.convs.append(nn.Conv1d(in_channels = 2*embed_size, \n","                                        out_channels = c, \n","                                        kernel_size = k))\n","\n","    def forward(self, inputs):\n","        # 将两个形状是(批量大小, 词数, 词向量维度)的嵌入层的输出按词向量连结\n","        embeddings = torch.cat((\n","            self.embedding(inputs), \n","            self.constant_embedding(inputs)), dim=2) # (batch, seq_len, 2*embed_size)\n","        # 根据Conv1D要求的输入格式，将词向量维，即一维卷积层的通道维(即词向量那一维)，变换到前一维\n","        embeddings = embeddings.permute(0, 2, 1)\n","        # 对于每个一维卷积层，在时序最大池化后会得到一个形状为(批量大小, 通道大小, 1)的\n","        # Tensor。使用flatten函数去掉最后一维，然后在通道维上连结\n","        encoding = torch.cat([self.pool(F.relu(conv(embeddings))).squeeze(-1) for conv in self.convs], dim=1)\n","        # 应用丢弃法后使用全连接层得到输出\n","        outputs = self.decoder(self.dropout(encoding))\n","        return outputs"],"metadata":{"id":"lqFBEpjGUgRN","executionInfo":{"status":"ok","timestamp":1673532202223,"user_tz":-480,"elapsed":313,"user":{"displayName":"万万仕文","userId":"18414854955088658758"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["embed_size, kernel_sizes, nums_channels = 100, [3, 4, 5], [100, 100, 100]\n","net = TextCNN(vocab, embed_size, kernel_sizes, nums_channels)"],"metadata":{"id":"Oix62YaLUlUL","executionInfo":{"status":"ok","timestamp":1673532205857,"user_tz":-480,"elapsed":344,"user":{"displayName":"万万仕文","userId":"18414854955088658758"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["glove_vocab = Vocab.GloVe(name='6B', dim=100, cache=os.path.join(DATA_ROOT, \"glove\"))\n","net.embedding.weight.data.copy_(\n","    d2l.load_pretrained_embedding(vocab.itos, glove_vocab))\n","net.constant_embedding.weight.data.copy_(\n","    d2l.load_pretrained_embedding(vocab.itos, glove_vocab))\n","net.constant_embedding.weight.requires_grad = False"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eRyo2SWGUofr","executionInfo":{"status":"ok","timestamp":1673532210032,"user_tz":-480,"elapsed":1925,"user":{"displayName":"万万仕文","userId":"18414854955088658758"}},"outputId":"08ea29cf-5637-4b39-82c6-bd0982e46249"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["There are 12998 oov words.\n","There are 12998 oov words.\n"]}]},{"cell_type":"code","source":["lr, num_epochs = 0.001, 5\n","optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, net.parameters()), lr=lr)\n","loss = nn.CrossEntropyLoss()\n","d2l.train(train_iter, test_iter, net, loss, optimizer, device, num_epochs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qqqf70QHUu9U","executionInfo":{"status":"ok","timestamp":1673532262589,"user_tz":-480,"elapsed":48548,"user":{"displayName":"万万仕文","userId":"18414854955088658758"}},"outputId":"a528ab7c-3f3a-4f50-fda8-4f16eb061230"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["training on  cuda\n","epoch 1, loss 0.3542, train acc 0.858, test acc 0.662, time 13.8 sec\n","epoch 2, loss 0.1161, train acc 0.904, test acc 0.667, time 7.6 sec\n","epoch 3, loss 0.0511, train acc 0.943, test acc 0.702, time 7.5 sec\n","epoch 4, loss 0.0206, train acc 0.971, test acc 0.734, time 7.5 sec\n","epoch 5, loss 0.0077, train acc 0.987, test acc 0.743, time 7.6 sec\n"]}]},{"cell_type":"code","source":["d2l.predict_sentiment(net, vocab, ['this', 'movie', 'is', 'so', 'great'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"MlV7XxhDWPDg","executionInfo":{"status":"ok","timestamp":1673532266306,"user_tz":-480,"elapsed":334,"user":{"displayName":"万万仕文","userId":"18414854955088658758"}},"outputId":"82c0dd53-c8b0-4f7f-c82c-5f978df6f71d"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'positive'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["d2l.predict_sentiment(net, vocab, ['this', 'movie', 'is', 'diffclut', 'to','understand'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"F0Q0RWoYWXJh","executionInfo":{"status":"ok","timestamp":1673532270126,"user_tz":-480,"elapsed":847,"user":{"displayName":"万万仕文","userId":"18414854955088658758"}},"outputId":"d81c1a0f-a95c-43f9-f1f8-2715627796df"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'negative'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["d2l.predict_sentiment(net, vocab, ['this', 'bird', 'looks','very','beautiful'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"g9MxAxZuWiYc","executionInfo":{"status":"ok","timestamp":1673532272993,"user_tz":-480,"elapsed":402,"user":{"displayName":"万万仕文","userId":"18414854955088658758"}},"outputId":"6fac9d69-1aee-4689-d256-555a37893e54"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'positive'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["d2l.predict_sentiment(net, vocab, ['I', 'dont', 'like','this','shirt'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"wWTupz_PWzcO","executionInfo":{"status":"ok","timestamp":1673532275209,"user_tz":-480,"elapsed":340,"user":{"displayName":"万万仕文","userId":"18414854955088658758"}},"outputId":"aae1466a-d425-4e61-94c9-8bd087f1274c"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'negative'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["d2l.predict_sentiment(net, vocab, ['your','hiar', 'looks', 'very','beatiful'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"hcpI7r9mW_T4","executionInfo":{"status":"ok","timestamp":1673532301544,"user_tz":-480,"elapsed":8,"user":{"displayName":"万万仕文","userId":"18414854955088658758"}},"outputId":"c979e5b2-f864-4378-af02-d3a47fb20f87"},"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'positive'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":28}]}]}